# Projet Hadoop MapReduce - 2026
**Auteur** : Soumaila
**Contact R√©f√©rent** : Sergio Simonian
**Dossier** : `projetHadoop`

---

## üìå Pr√©sentation du Projet
Ce projet consiste en la r√©solution de trois probl√®mes distincts d'analyse de donn√©es massives en utilisant le framework Hadoop MapReduce. L'objectif est de d√©montrer une capacit√© √† manipuler des datasets vari√©s (mots, transactions commerciales, donn√©es d'apprentissage OULAD) en optimisant les phases de Shuffle & Sort et de Partitionnement.

## üõ† Structure du R√©pertoire
```bash
projetHadoop/
‚îú‚îÄ‚îÄ RhymeFinder.java            # Partie 1 : D√©tecteur de rimes
‚îú‚îÄ‚îÄ MarketBasketAnalysis.java   # Partie 2 : Analyse de panier
‚îú‚îÄ‚îÄ OuladRecommendation.java    # Partie 3 : Syst√®me de recommandation
‚îú‚îÄ‚îÄ run_project.sh              # Script d'automatisation (Partie 3)
‚îú‚îÄ‚îÄ generate_oulad_large.py     # Script de g√©n√©ration synth√©tique (OULAD)
‚îú‚îÄ‚îÄ generate_transactions.py    # Script de g√©n√©ration transactions
‚îú‚îÄ‚îÄ patterns/                   # Dossier KIs et Documentation
‚îú‚îÄ‚îÄ Resultats_Finaux/           # Sorties standard
‚îú‚îÄ‚îÄ Resultats_Gros_Volume/      # Sorties "Big Data"
‚îú‚îÄ‚îÄ LIVRABLES.md                # Documentation technique d√©taill√©e
‚îî‚îÄ‚îÄ README.md                   # Ce fichier
```

## üöÄ Instructions d'Ex√©cution

### Partie 1 : D√©tecteur de Rimes (5 points)
**Objectif** : Identifier les mots de plus de 5 caract√®res partageant les 4 m√™mes derniers caract√®res.
**Complexit√©** : O(n)

**Ex√©cution** :
```bash
# Compilation
javac -classpath `hadoop classpath` -d build RhymeFinder.java
jar -cvf rhyme-finder.jar -C build/ .

# Split du fichier en 5 parties √©gales
split -n l/5 -d common_words_en_subset.txt part_

# Envoi sur HDFS
hdfs dfs -mkdir -p /user/etudiant/projetHadoop/input
hdfs dfs -put part_* /user/etudiant/projetHadoop/input/

# Lancement du Job
hdfs dfs -rm -r /user/etudiant/projetHadoop/RhymeResult
hadoop jar rhyme-finder.jar RhymeFinder /user/etudiant/projetHadoop/input /user/etudiant/projetHadoop/RhymeResult
```

### Partie 2 : Analyse du Panier (5 points)
**Objectif** : Extraire toutes les paires d'articles co-occurrentes et leurs transactions.
**Logique** : Utilisation d'un tri alphab√©tique des paires dans le Mapper pour √©viter les doublons invers√©s.

**Ex√©cution** :
```bash
# Compilation (Mise √† jour du JAR)
javac -classpath `hadoop classpath` -d build MarketBasketAnalysis.java
jar -uvf rhyme-finder.jar -C build/ .

# Ingestion
wget https://cours.aiaoma.com/transactions.txt
hdfs dfs -put transactions.txt /user/etudiant/projetHadoop/input/

# Lancement du Job
hdfs dfs -rm -r /user/etudiant/projetHadoop/CommonItems
hadoop jar rhyme-finder.jar MarketBasketAnalysis /user/etudiant/projetHadoop/input/transactions.txt /user/etudiant/projetHadoop/CommonItems
```

### Partie 3 : Syst√®me de Recommandation (10 points)
**Ce pipeline est compos√© de 5 Jobs successifs :**
1.  **Join & Filter** : Jointure entre `student_vle` et `vle` sur le module DDD.
2.  **Aggregation** : Somme des clics par √©tudiant/activit√©.
3.  **Unique Features** : Extraction des colonnes de la matrice.
4.  **Pivot** : Transformation Long-to-Wide (Matrice creuse) via DistributedCache.
5.  **Scoring** : Calcul des recommandations (Map-only).

**Ex√©cution Automatis√©e (Via Docker)** :

Ce projet est configur√© pour tourner sur un environnement **Docker** local.

1.  **D√©marrer le cluster** :
    ```powershell
    docker-compose up -d
    ```

2.  **Lancer le Pipeline Complet** :
    ```powershell
    # Connectez-vous au conteneur client
    docker exec -it hadoop-client bash
    
    # (Une fois dans le conteneur)
    cd /app
    ./run_project.sh
    ```

Le script `run_project.sh` se charge de :
*   Compiler les codes Java.
*   Ing√©rer les fichiers CSV (pr√©sents localement ou t√©l√©charg√©s).
*   Ex√©cuter les 5 Jobs MapReduce.
*   Afficher les r√©sultats du scoring. 

## ‚öñÔ∏è Grille d'√âvaluation (Auto-√©valuation)
*   **Exactitude (50%)** : Solutions test√©es sur les datasets fournis, respect strict des crit√®res de filtrage (ex: longueur > 5 pour les rimes, codes modules DDD).
*   **Qualit√© (50%)** :
    *   Code Java document√© et modulaire.
    *   Architecture O(n) pour les rimes.
    *   Gestion efficace du DistributedCache pour le Pivot.
    *   Scripts shell fournis pour la reproductibilit√©.

## üìù D√©marches Suivies
*   **Rimes** : Utilisation du suffixe comme cl√© de partitionnement pour forcer le regroupement naturel des mots qui riment lors du Shuffle.
*   **Panier** : Algorithme de calcul de paires (n*(n-1)/2) par transaction avec normalisation des cl√©s (tri).
*   **Recommandation** : Gestion des valeurs manquantes (clics = 0) lors du pivot pour assurer une matrice dense en sortie.

## üìà Scalabilit√© et Gros Volumes
Le projet a √©t√© test√© avec succ√®s sur un jeu de donn√©es √©tendu pour prouver la robustesse de l'impl√©mentation Hadoop.



### R√©sultats
L'ex√©cution produit les r√©sultats dans le dossier `Resultats_Finaux`.

## üìÇ Acc√®s √† HDFS (Hadoop Distributed File System)

### Option 1 : Ligne de Commande (CLI)
Via le conteneur Docker `hadoop-client` :

```bash
# Lister les fichiers du projet
docker exec hadoop-client hdfs dfs -ls -R /user/etudiant/projetHadoop

# Lire le d√©but d'un fichier (ex: r√©sultat rimes)
docker exec hadoop-client hdfs dfs -head /user/etudiant/projetHadoop/RhymeResult/part-r-00000

# Shell interactif
docker exec -it hadoop-client bash
# (Dedans) hdfs dfs -ls /
```

### Option 2 : Interface Web (NameNode UI)
Si les ports sont ouverts, acc√©dez √† l'interface graphique :
*   **URL** : [http://localhost:9870](http://localhost:9870)
*   **Navigation** : Menu "Utilities" > "Browse the file system".

### Chemins Cl√©s
*   **Input** : `/user/etudiant/projetHadoop/input`
*   **Output Rimes** : `/user/etudiant/projetHadoop/RhymeResult`
*   **Output Panier** : `/user/etudiant/projetHadoop/CommonItems`
*   **Output OULAD** : `/user/etudiant/projetHadoop/oulad_output/`
